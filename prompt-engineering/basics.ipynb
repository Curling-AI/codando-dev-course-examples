{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d54f5da-4bd8-4c32-913b-9def60be22e0",
   "metadata": {},
   "source": [
    "### Configura√ß√£o (comece por aqui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fd9394-0412-4366-bb40-eb3f268fbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "const GOOGLE_API_KEY = 'AIzaSyBcZaRAsEEAASg1fLcpAt_-qml53ypr3Cg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70dc4504-d41c-47dd-a85f-273605f85872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatGoogleGenerativeAI } from 'npm:@langchain/google-genai'\n",
    "\n",
    "let model = new ChatGoogleGenerativeAI({\n",
    "    apiKey: GOOGLE_API_KEY,\n",
    "    model: \"gemini-2.5-flash-lite\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cda511fb-0d5a-4dde-a7c0-c34cedaef068",
   "metadata": {},
   "outputs": [],
   "source": [
    "const display = {\n",
    "    md: (txt) => Deno.jupyter.display({\n",
    "  \"text/markdown\": txt,\n",
    "}, { raw: true }),\n",
    "    txt: (txt) => Deno.jupyter.display({\n",
    "  \"text/plain\": txt,\n",
    "}, { raw: true }),\n",
    "    html: (txt) => Deno.jupyter.display({\n",
    "  \"text/markdown\": txt,\n",
    "}, { raw: true })\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c911b-2be1-4a49-b846-aee6ad7777b2",
   "metadata": {},
   "source": [
    "# B√°sico de Prompting\n",
    "\n",
    "## O que √© um prompt?\n",
    "\n",
    "Um prompt √© a entrada que a LLM usar√° para inferir (gerar) uma sa√≠da. \n",
    "\n",
    "Voc√™ pode ir muito longe com prompts b√°sicos, mas a qualidade da sa√≠da de uma LLM depende diretamente do qu√£o bom o prompt √©.\n",
    "\n",
    "Prompts geralmente possuem um formato de **pergunta** ou **instru√ß√£o**, mas frequentemente precisa conter elementos como **contexto** e **exemplos**.\n",
    "\n",
    "Vamos para o exemplo mais simples de um prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba68c70-5222-4d97-b7f2-c5e0693c3700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "O c√©u √© uma vasta e fascinante ab√≥bada azul que cobre a Terra. Ele √© composto principalmente por gases como nitrog√™nio e oxig√™nio, e √© onde vemos o sol, a lua e as estrelas.\n",
       "\n",
       "Mas \"c√©u\" pode ter muitos significados, dependendo do contexto:\n",
       "\n",
       "*   **Em Astronomia:** √â o espa√ßo sideral que observamos da Terra, incluindo planetas, estrelas, gal√°xias e outros corpos celestes.\n",
       "*   **Em Meteorologia:** √â a atmosfera, onde ocorrem os fen√¥menos clim√°ticos como nuvens, chuva, vento e trov√µes.\n",
       "*   **Em Geografia:** √â a por√ß√£o vis√≠vel acima da superf√≠cie terrestre.\n",
       "*   **Em um sentido figurado ou espiritual:** O c√©u pode representar um lugar de paz, felicidade, para√≠so, ou um estado de esp√≠rito elevado.\n",
       "\n",
       "Voc√™ pensava em alguma dessas defini√ß√µes em particular? Ou talvez tenha outra coisa em mente quando diz \"o c√©u √©\"? üòä"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke('O c√©u √©')\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd157a1-9135-4038-94ea-8093b4329bfe",
   "metadata": {},
   "source": [
    "Voc√™ pode observar que, embora o modelo tenha respondido algo no contexto do prompt, se o nosso objetivo √© que ele simplesmente complete a frase, o resultado est√° bem longe de cumprir esta tarefa.\n",
    "\n",
    "Ou seja, mesmo em um exemplo t√£o simples quanto esse, fica claro o qu√£o necess√°rio √© prover mais contexto ou instru√ß√µes mais espec√≠ficas sobre a tarefa em quest√£o.\n",
    "\n",
    "Esse √© o princ√≠pio de **Prompt Engineering**.\n",
    "\n",
    "Vamos tentar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b8b3a6-c465-4b96-8baa-b2d638fb9b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "O c√©u √©... **azul** (na maioria das vezes)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Apenas complete a frase:\n",
    "O c√©u √©...\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f164c-4477-4259-bd59-3719a33b6bf2",
   "metadata": {},
   "source": [
    "Melhor, n√©?\n",
    "\n",
    "Essa abordagem de projetar prompts para garantir que resolvam uma tarefa de forma acurada √© chamada de **Prompt Engineering**\n",
    "\n",
    "## Formatos de Prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f21af9-1ccf-4207-9c71-5bcefd1058cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
