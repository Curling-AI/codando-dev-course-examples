{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d54f5da-4bd8-4c32-913b-9def60be22e0",
   "metadata": {},
   "source": [
    "### Configuração (comece por aqui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd9394-0412-4366-bb40-eb3f268fbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "const GOOGLE_API_KEY = '' // SEU ID DA API DO GOOGLE AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70dc4504-d41c-47dd-a85f-273605f85872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatGoogleGenerativeAI } from 'npm:@langchain/google-genai'\n",
    "\n",
    "let model = new ChatGoogleGenerativeAI({\n",
    "    apiKey: GOOGLE_API_KEY,\n",
    "    model: \"gemini-2.5-flash-lite\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda511fb-0d5a-4dde-a7c0-c34cedaef068",
   "metadata": {},
   "outputs": [],
   "source": [
    "const display = {\n",
    "    md: (txt) => Deno.jupyter.display({\n",
    "      \"text/markdown\": txt,\n",
    "    }, { raw: true }),\n",
    "    txt: (txt) => Deno.jupyter.display({\n",
    "      \"text/plain\": txt,\n",
    "    }, { raw: true }),\n",
    "    html: (txt) => Deno.jupyter.display({\n",
    "      \"text/markdown\": txt,\n",
    "    }, { raw: true })\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c911b-2be1-4a49-b846-aee6ad7777b2",
   "metadata": {},
   "source": [
    "# Básico de Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a31bf-033e-4967-9736-a18cc86b2438",
   "metadata": {},
   "source": [
    "## O que é um prompt?\n",
    "\n",
    "Um prompt é a entrada que a LLM usará para inferir (gerar) uma saída. \n",
    "\n",
    "Você pode ir muito longe com prompts básicos, mas a qualidade da saída de uma LLM depende diretamente do quão bom o prompt é.\n",
    "\n",
    "Prompts geralmente possuem um formato de **pergunta** ou **instrução**, mas frequentemente precisa conter elementos como **contexto** e **exemplos**.\n",
    "\n",
    "Vamos para o exemplo mais simples de um prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba68c70-5222-4d97-b7f2-c5e0693c3700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "O céu é um conceito multifacetado, com significados que se estendem para além da atmosfera terrestre. Aqui estão algumas das interpretações mais comuns:\n",
       "\n",
       "**No sentido literal/científico:**\n",
       "\n",
       "*   **A atmosfera terrestre:** É a camada de gases que envolve a Terra. É onde ocorrem fenômenos meteorológicos como nuvens, chuva, vento e relâmpagos. O céu, visto da Terra, é o resultado da interação da luz solar com essa atmosfera.\n",
       "*   **O espaço exterior:** Quando falamos do céu em um contexto astronômico, nos referimos ao espaço além da atmosfera terrestre, onde estão as estrelas, planetas, galáxias e outros corpos celestes.\n",
       "\n",
       "**No sentido figurado/cultural/religioso:**\n",
       "\n",
       "*   **Um lugar de paz e tranquilidade:** Frequentemente associado a um estado de serenidade, harmonia e ausência de problemas.\n",
       "*   **O paraíso/morada divina:** Em muitas religiões, o céu é concebido como o local onde os justos vão após a morte, um lugar de felicidade eterna em comunhão com uma divindade.\n",
       "*   **O limite/o máximo:** Pode ser usado para indicar o ponto mais alto possível, o limite de algo. \"O céu é o limite\" significa que não há restrições.\n",
       "*   **O firmamento:** A abóbada celeste que vemos durante o dia (azul) e à noite (estrelada).\n",
       "\n",
       "**Em resumo, o céu pode ser:**\n",
       "\n",
       "*   **A vastidão azul acima de nós durante o dia.**\n",
       "*   **O universo escuro pontilhado de estrelas à noite.**\n",
       "*   **Um ideal de perfeição e felicidade.**\n",
       "*   **Um destino espiritual.**\n",
       "\n",
       "Qual dessas definições você tinha em mente? Ou você estava pensando em algo mais?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke('O céu é')\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd157a1-9135-4038-94ea-8093b4329bfe",
   "metadata": {},
   "source": [
    "Você pode observar que, embora o modelo tenha respondido algo no contexto do prompt, se o nosso objetivo é que ele simplesmente complete a frase, o resultado está bem longe de cumprir esta tarefa.\n",
    "\n",
    "Ou seja, mesmo em um exemplo tão simples quanto esse, fica claro o quão necessário é prover mais contexto ou instruções mais específicas sobre a tarefa em questão.\n",
    "\n",
    "Esse é o princípio de **Prompt Engineering**.\n",
    "\n",
    "Vamos tentar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b8b3a6-c465-4b96-8baa-b2d638fb9b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "O céu é... **azul**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Apenas complete a frase:\n",
    "O céu é...\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f164c-4477-4259-bd59-3719a33b6bf2",
   "metadata": {},
   "source": [
    "Melhor, né?\n",
    "\n",
    "Essa abordagem de projetar prompts para garantir que resolvam uma tarefa de forma acurada é chamada de **Prompt Engineering**.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f21af9-1ccf-4207-9c71-5bcefd1058cf",
   "metadata": {},
   "source": [
    "## Formatos de Prompts\n",
    "\n",
    "Tentamos um prompt muito simples acima. Um prompt padrão tem o seguinte formato:\n",
    "\n",
    "```\n",
    "<Pergunta>?\n",
    "```\n",
    "\n",
    "ou\n",
    "\n",
    "```\n",
    "<Instrução>\n",
    "```\n",
    "\n",
    "Isso pode ser formatado em um formato de resposta a perguntas (Q&A), que é padrão em muitos conjuntos de dados de QA, como segue:\n",
    "\n",
    "```\n",
    "Q: <Pergunta>?\n",
    "A:\n",
    "```\n",
    "\n",
    "Ao solicitar como o acima, também chamado de **Zero Shot Prompt**, ou seja, você está solicitando diretamente ao modelo uma resposta sem nenhum exemplo ou demonstração sobre a tarefa que deseja realizar.\n",
    "\n",
    "Alguns modelos de linguagem grandes têm a capacidade de executar prompts zero-shot, mas isso depende da complexidade e do conhecimento da tarefa em questão.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Dado o formato padrão acima, uma técnica popular e eficaz para solicitação é chamada de **Few Shot Prompt**, onde fornecemos exemplos (ou seja, demonstrações). \n",
    "\n",
    "Os prompts de poucos tiros podem ser formatados da seguinte maneira:\n",
    "\n",
    "```\n",
    "<Pergunta>?\n",
    "<Resposta>\n",
    "<Pergunta>?\n",
    "<Resposta>\n",
    "<Pergunta>?\n",
    "<Resposta>\n",
    "<Pergunta>?\n",
    "```\n",
    "\n",
    "A versão do formato QA ficaria assim:\n",
    "\n",
    "```\n",
    "Q: <Pergunta>?\n",
    "A: <Resposta>\n",
    "Q: <Pergunta>?\n",
    "A: <Resposta>\n",
    "Q: <Pergunta>?\n",
    "A: <Resposta>\n",
    "Q: <Pergunta>?\n",
    "A:\n",
    "```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Lembre-se de que não é necessário usar o formato QA.\n",
    "O formato do prompt depende da tarefa em mãos.\n",
    "Por exemplo, você pode executar uma tarefa de classificação simples e fornecer exemplares que demonstrem a tarefa da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dba70cc-9dcd-4efb-94a2-629336f8586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Negativo"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Isso é incrível! // Positivo\n",
    "Isto é mau! // Negativo\n",
    "Uau, esse filme foi radical! // Positivo\n",
    "Que espetáculo horrível! //\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74c26d-e5d2-4d03-a5b8-5d6312b982d5",
   "metadata": {},
   "source": [
    "Os prompts de poucos tiros permitem o aprendizado no contexto, que é a capacidade dos modelos de linguagem de aprender tarefas dadas algumas demonstrações.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180711d8-8d1f-4960-abe8-982790b58355",
   "metadata": {},
   "source": [
    "## Elementos de um Prompt\n",
    "\n",
    "Um prompt pode conter qualquer um dos seguintes componentes:\n",
    "\n",
    "- **Instrução** - uma tarefa ou instrução específica que você deseja que o modelo execute.\n",
    "\n",
    "- **Contexto** - pode envolver informações externas ou contexto adicional que pode direcionar o modelo para melhores respostas.\n",
    "\n",
    "- **Dados de entrada** - é a entrada ou pergunta para a qual estamos interessados em encontrar uma resposta.\n",
    "\n",
    "- **Indicador de saída** - indica o tipo ou formato da saída.\n",
    "\n",
    "Nem todos os componentes são necessários para um prompt e o formato depende da tarefa em questão. Abordaremos exemplos mais concretos nos próximos guias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "820de027-aac8-4414-88f8-4433e811306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sentimento: Negativo"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Classifique o texto entre neutro, negativo ou positivo\n",
    "\n",
    "Texto: Que espetáculo horrível!.\n",
    "\n",
    "Sentimento:\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f87e61-8b2e-4b98-8835-cfee3511ae61",
   "metadata": {},
   "source": [
    "Perceba que este exemplo possui instrução, dados de entrada e indicadoor de saída, mas não inclui contexto (como no exemplo de few-shot acima).\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007d43e7-61b6-44ad-8ca2-24a9155bc183",
   "metadata": {},
   "source": [
    "## Dicas Gerais para Projetar Prompts\n",
    "\n",
    "Aqui estão |algumas dicas para ter em mente enquanto você projeta seus prompts:\n",
    "\n",
    "### Comece Simples\n",
    "\n",
    "- Procure um ambiente limpo de \"System prompts\" (Ex. OpenAI Playground, Google AI Studio) e crie uma \"biblioteca de prompts\".\n",
    "- Você pode começar com prompts simples e continuar adicionando mais elementos e contexto conforme busca resultados melhores. \n",
    "- Iterar seu prompt ao longo do tempo é vital por essa razão.\n",
    "- Vamos passar muitos exemplos onde especificidade, simplicidade e concisão frequentemente darão melhores resultados.\n",
    "\n",
    "- Quando você tem uma tarefa grande que envolve muitas subtarefas diferentes, pode tentar dividir a tarefa em subtarefas mais simples e continuar construindo conforme obtém resultados melhores.\n",
    "- Isso evita adicionar muita complexidade ao processo de design de prompts no início.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### A Instrução\n",
    "\n",
    "- Você pode projetar prompts eficazes para várias tarefas simples usando *comandos* ou *palavras-chave* para instruir o modelo sobre o que deseja alcançar, como \"Escreva\", \"Classifique\", \"Resuma\", \"Traduza\", \"Ordene\", etc.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Tenha em mente que você também precisa experimentar muito para ver o que funciona melhor.\n",
    "- Tente diferentes instruções com diferentes palavras-chave, contextos e dados e veja o que funciona melhor para seu caso de uso e tarefa específicos.\n",
    "- Geralmente, **quanto mais específico e relevante o contexto for para a tarefa que você está tentando realizar, melhor**.\n",
    "\n",
    "<br>\n",
    "\n",
    "- É recomendado que você coloque as instruções no início do prompt ou no **system prompt**. \n",
    "- Outra recomendação é usar algum **separador** claro como \"###\" para separar a instrução do contexto.\n",
    "\n",
    "Por exemplo:\n",
    "\n",
    "*Prompt:*\n",
    "```\n",
    "### Instrução ###\n",
    "Traduza o texto abaixo para o espanhol:\n",
    "\n",
    "Texto: \"hello!\"\n",
    "```\n",
    "\n",
    "*Saída:*\n",
    "```\n",
    "¡Hola!\n",
    "```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Especificidade\n",
    "\n",
    "- Seja muito **específico** sobre a instrução e tarefa que você quer que o modelo execute.\n",
    "- Quanto mais descritivo e detalhado o prompt for, melhores serão os resultados.\n",
    "- Isso é particularmente importante quando você tem um resultado desejado ou estilo de geração que está buscando.\n",
    "- **Não há tokens ou palavras-chave específicas que levem a resultados melhores.**\n",
    "- É mais importante ter um bom formato e um prompt descritivo.\n",
    "- Então geralmente, fornecer exemplos no prompt é a melhor maneira de obter a saída desejada em formatos específicos.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Ao projetar prompts, você também deve ter em mente o tamanho do prompt, pois há limitações sobre quão longo o prompt pode ser.\n",
    "- Pense em quão específico e detalhado você deve ser.\n",
    "- Incluir muitos detalhes desnecessários não é necessariamente uma boa abordagem.\n",
    "- Os detalhes devem ser relevantes e contribuir para a tarefa em questão.\n",
    "- Isso é algo que você precisará experimentar bastante.\n",
    "- É necessário muita experimentação e iteração para otimizar prompts para suas aplicações.\n",
    "\n",
    "Agora, vamos tentar um prompt simples para extrair informações específicas de um trecho de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60954676-fcfb-4fe8-8a00-99bb143a64c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Lugar: Centro Champalimaud para o Desconhecido, Lisboa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Extraia o nome dos lugares no seguinte texto.\n",
    "\n",
    "Formato desejado:\n",
    "Lugar: <lista_de_lugares_separados_por_vírgula>\n",
    "\n",
    "Entrada: \n",
    "\"Embora esses desenvolvimentos sejam encorajadores para os pesquisadores, muito ainda é um mistério. \n",
    "\"Frequentemente temos uma caixa preta entre o cérebro e o efeito que vemos na periferia,\" diz Henrique Veiga-Fernandes, \n",
    "um neuroimunologista no Centro Champalimaud para o Desconhecido em Lisboa. \n",
    "\"Se queremos usá-lo no contexto terapêutico, precisamos realmente entender o mecanismo.\"\"\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8252c-9f91-412b-960d-109077af20c6",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Evite Imprecisão\n",
    "\n",
    "- Dadas as dicas acima sobre ser detalhado e melhorar o formato, é fácil cair na armadilha de querer ser muito inteligente com os prompts e potencialmente criar descrições imprecisas.\n",
    "- Frequentemente é melhor ser específico e direto.\n",
    "- A analogia aqui é muito similar à comunicação eficaz -- quanto mais direta, mais eficaz a mensagem é transmitida.\n",
    "\n",
    "Por exemplo, você pode estar interessado em aprender o conceito de engenharia de prompts. Você pode tentar algo como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9458dfdf-2fc3-4932-a418-90bbe4ac0649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Engenharia de prompts é a arte e ciência de projetar e otimizar as instruções dadas a modelos de IA para obter resultados desejados. Trata-se de refinar a entrada para guiar o modelo de forma eficaz."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Explique o conceito de engenharia de prompts. Mantenha a explicação curta, apenas algumas frases, e não seja muito descritivo.\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1514de81-e262-4e2f-93b8-54204b60bc5f",
   "metadata": {},
   "source": [
    "Não está claro no prompt acima quantas frases usar e qual estilo.\n",
    "Você ainda pode obter boas respostas com os prompts acima, mas o melhor prompt seria aquele que é muito específico, conciso e direto ao ponto.\n",
    "Algo como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5e9e63e-a7d4-4690-9bdf-3f166c15c50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Engenharia de prompts é a arte de criar instruções claras e eficazes para modelos de inteligência artificial, como o que estou usando agora. Pense nisso como dar instruções específicas a um amigo robô para que ele entenda exatamente o que você quer e te ajude da melhor forma possível. Quanto melhores forem seus \"prompts\" (as instruções), melhores serão as respostas que você receberá."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Use 2-3 frases para explicar o conceito de engenharia de prompts para um estudante do ensino médio.\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450cd7b-ee1e-4ad0-8060-a2bc3a4c380b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Fazer ou não fazer?\n",
    "\n",
    "- Outra dica comum ao projetar prompts **é evitar dizer o que não fazer**, mas dizer o que fazer em vez disso.\n",
    "- Isso encoraja mais especificidade e foca nos detalhes que levam a boas respostas do modelo.\n",
    "\n",
    "Aqui está um exemplo de um chatbot de recomendação de filmes falhandoem exatamente o que eu não quero que ele faça por causa de como escrevi a instrução -- focando no que não fazer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "534dafa1-cc32-436a-a3f9-8cc93b275897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Entendido. Com base nos meus dados, posso recomendar um filme que tem tido grande sucesso de crítica e público.\n",
       "\n",
       "Você gostaria de saber sobre:\n",
       "\n",
       "*   **\"Parasita\"**: Um thriller sul-coreano que ganhou o Oscar de Melhor Filme, conhecido por sua abordagem inteligente e chocante das desigualdades sociais.\n",
       "*   **\"Duna\"**: Uma épica aventura de ficção científica visualmente deslumbrante, baseada no aclamado romance.\n",
       "*   **\"Nomadland\"**: Um drama comovente e contemplativo sobre uma mulher que viaja pelos Estados Unidos após perder tudo na Grande Recessão.\n",
       "\n",
       "Qual dessas opções lhe parece mais interessante?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "O seguinte é um agente que recomenda filmes para um cliente. NÃO PERGUNTE SOBRE INTERESSES. NÃO PERGUNTE SOBRE INFORMAÇÕES PESSOAIS.\n",
    "\n",
    "Cliente: Por favor, recomende um filme baseado nos meus interesses.\n",
    "Agente: \n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1e67c-3fe9-40f5-a0df-f58e4e2cbce3",
   "metadata": {},
   "source": [
    "Aqui está um prompt melhor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9efc255-0e9d-4482-9648-6785eb8c1a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Desculpe, não consegui encontrar um filme para recomendar hoje."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "O seguinte é um agente que recomenda filmes para um cliente.\n",
    "O agente é responsável por recomendar um filme dos principais filmes em alta globalmente. \n",
    "Ele deve se abster de perguntar aos usuários sobre suas preferências e evitar pedir informações pessoais. \n",
    "Se o agente não tiver um filme para recomendar, deve responder \"Desculpe, não consegui encontrar um filme para recomendar hoje.\".\n",
    "\n",
    "Cliente: Por favor, recomende um filme baseado nos meus interesses.\n",
    "Agente:\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d3d51-2eda-4870-8ead-47e18bdae6bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de27c11-7ba9-42d0-bc75-4a43ab0193ca",
   "metadata": {},
   "source": [
    "## Exemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738bd880-31f3-4317-ae16-4baa585d3b81",
   "metadata": {},
   "source": [
    "### Resumo de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffcae92-6231-4df5-990c-6ee5da06da53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Artigos de pesquisa devem declarar o uso de IA, como ChatGPT, e os periódicos devem ser transparentes sobre o uso de LLMs para garantir rigor e creditação adequada."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Declarações de contribuição de autores e agradecimentos em artigos de pesquisa devem declarar de forma clara e específica se, e em que medida, os autores usaram tecnologias de IA como ChatGPT na preparação de seu manuscrito e análise. Eles também devem indicar quais LLMs foram usados. Isso alertará editores e revisores para examinar os manuscritos com mais cuidado em busca de possíveis vieses, imprecisões e creditação inadequada de fontes. Da mesma forma, periódicos científicos devem ser transparentes sobre o uso de LLMs, por exemplo, ao selecionar manuscritos submetidos.\n",
    "\n",
    "Resuma o texto acima é uma frase.\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76094e0-bbc6-4467-bb99-3577cc8e8104",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ffca7-af40-4c2d-a57e-b288f081156b",
   "metadata": {},
   "source": [
    "### Extração de Informação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee648f8f-86ac-4321-9efd-8b9fac979a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "O produto baseado em modelo de LLM mencionado no parágrafo é o **ChatGPT**."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Declarações de contribuição de autores e agradecimentos em artigos de pesquisa devem declarar de forma clara e específica se, e em que medida, os autores usaram tecnologias de IA como ChatGPT na preparação de seu manuscrito e análise. Eles também devem indicar quais LLMs foram usados. Isso alertará editores e revisores para examinar os manuscritos com mais cuidado em busca de possíveis vieses, imprecisões e creditação inadequada de fontes. Da mesma forma, periódicos científicos devem ser transparentes sobre o uso de LLMs, por exemplo, ao selecionar manuscritos submetidos.\n",
    "\n",
    "Mencione o produto baseado em modelo de LLM mencionado no parágrafo acima.\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52431510-7c09-425d-baff-a47da8ee0fa1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ce601-fe8d-4647-9ff0-29b842404dce",
   "metadata": {},
   "source": [
    "### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5afc2a7d-2621-4c4c-9e1c-cda1053f4a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Camundongos"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Responda à pergunta com base no contexto abaixo. \n",
    "Mantenha a resposta curta e concisa. \n",
    "Responda \"Não tenho certeza sobre a resposta\" se não tiver certeza sobre a resposta.\n",
    "\n",
    "Contexto: Teplizumab tem suas raízes em uma empresa farmacêutica de Nova Jersey chamada Ortho Pharmaceutical. Lá, cientistas geraram uma versão inicial do anticorpo, apelidado de OKT3. Originalmente obtido de camundongos, a molécula foi capaz de se ligar à superfície das células T e limitar seu potencial de destruição celular. Em 1986, foi aprovado para ajudar a prevenir a rejeição de órgãos após transplantes de rim, tornando-se o primeiro anticorpo terapêutico permitido para uso humano.\n",
    "\n",
    "Pergunta: De onde o OKT3 foi originalmente obtido?\n",
    "\n",
    "Resposta:\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77b948-d8f1-491f-af0d-0383b132d5e1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be6bbf-cb5a-437a-b035-b6f0e98f9c05",
   "metadata": {},
   "source": [
    "### Classificação de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8571db48-5559-4a70-86bf-94f35dd19096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "neutro"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Classifique o texto como neutro, negativo ou positivo. \n",
    "\n",
    "Texto: Acho que as férias estão ok.\n",
    "Sentimento: neutro \n",
    "\n",
    "Texto: Acho que a comida estava ok. \n",
    "Sentimento:\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7c0ee-8c10-4df4-af60-78bc40ea5bb1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bf0c0-34cf-48df-a58b-9ca8dcba43ab",
   "metadata": {},
   "source": [
    "### Geração de Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d2fd9f-73e4-40b4-82be-ea5685898a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "nome = input(\"Qual é o seu nome? \")\n",
       "print(\"Olá\", nome)\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "/*\n",
    "Produza somente cóodigo.\n",
    "Pergunte o nome do usuário e diga \"Olá\"\n",
    "*/\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9991cc-c406-4ca6-bcf3-e311d68c4ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```sql\n",
       "SELECT\n",
       "    s.StudentId,\n",
       "    s.StudentName\n",
       "FROM\n",
       "    students s\n",
       "JOIN\n",
       "    departments d ON s.DepartmentId = d.DepartmentId\n",
       "WHERE\n",
       "    d.DepartmentName = 'Ciência da Computação';\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "\"\"\"\n",
    "Produza somente cóodigo.\n",
    "Tabela departments, colunas = [DepartmentId, DepartmentName]\n",
    "Tabela students, colunas = [DepartmentId, StudentId, StudentName]\n",
    "Crie uma consulta MySQL para todos os estudantes do Departamento de Ciência da Computação\n",
    "\"\"\"\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303567f4-07a0-4f4e-a08c-df457724c273",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083202ab-087c-4979-bddb-c6514d4d1580",
   "metadata": {},
   "source": [
    "### Conversas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aa89fe8-95fd-4cf5-9436-2a5f413eef1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Absolutamente. A formação de buracos negros é um processo fascinante impulsionado pelos princípios da física estelar e da relatividade geral. Essencialmente, um buraco negro é uma região do espaço-tempo onde a gravidade é tão intensa que nada, nem mesmo partículas e radiação eletromagnética como a luz, consegue escapar de seu horizonte de eventos.\n",
       "\n",
       "A forma mais comum de formação de buracos negros que observamos e teorizamos é através do colapso gravitacional de estrelas massivas. O processo ocorre da seguinte maneira:\n",
       "\n",
       "1.  **Fase Estelar:** Estrelas massivas, com massas significativamente maiores que a do nosso Sol (tipicamente mais de 20 a 25 massas solares), gastam sua energia através da fusão nuclear em seus núcleos. Durante a maior parte de suas vidas, a pressão externa gerada pelas reações de fusão contrabalança a força esmagadora da gravidade interna.\n",
       "\n",
       "2.  **Esgotamento do Combustível Nuclear:** Quando a estrela esgota seu combustível nuclear, principalmente hidrogênio, hélio e elementos mais pesados, as reações de fusão no núcleo começam a diminuir ou cessar.\n",
       "\n",
       "3.  **Colapso Gravitacional:** Sem a pressão externa para sustentar a estrutura da estrela, a gravidade se torna a força dominante. O núcleo da estrela começa a implodir sob seu próprio peso. Essa implosão é incrivelmente rápida e violenta.\n",
       "\n",
       "4.  **Formação de uma Supernova:** A implosão do núcleo leva a um \"ressalto\" e a uma explosão cataclísmica conhecida como supernova. Durante a supernova, as camadas externas da estrela são ejetadas para o espaço, criando espetáculos luminosos que podem brilhar intensamente por semanas ou meses.\n",
       "\n",
       "5.  **Formação do Buraco Negro (ou Estrela de Nêutrons):** O destino do núcleo remanescente da estrela depende de sua massa:\n",
       "    *   Se a massa do núcleo remanescente for **inferior a aproximadamente 2-3 massas solares** (o limite de Tolman-Oppenheimer-Volkoff para estrelas de nêutrons), a implosão será interrompida pela pressão de degenerescência de nêutrons, formando uma **estrela de nêutrons**.\n",
       "    *   No entanto, se a massa do núcleo remanescente for **superior a este limite**, a pressão de degenerescência de nêutrons não é suficiente para deter o colapso gravitacional. A gravidade continua a comprimir a matéria, concentrando uma quantidade imensa de massa em um volume infinitesimal, teoricamente um ponto de densidade infinita chamado **singularidade**.\n",
       "\n",
       "6.  **Horizonte de Eventos:** À medida que a massa se condensa, o campo gravitacional ao seu redor se torna cada vez mais forte. Uma vez que a massa é comprimida a um determinado raio (o raio de Schwarzschild para um buraco negro não rotativo), a velocidade de escape desse ponto excede a velocidade da luz. Essa fronteira imaginária é o **horizonte de eventos**. Qualquer coisa que cruze o horizonte de eventos está irremediavelmente presa.\n",
       "\n",
       "Além da formação estelar, existem outras categorias de buracos negros teorizados:\n",
       "\n",
       "*   **Buracos Negros Supermassivos:** Encontrados nos centros da maioria das galáxias, incluindo a Via Láctea. Suas massas variam de milhões a bilhões de vezes a massa do Sol. Acredita-se que se formem através de processos de acreção contínua de matéria e fusão de buracos negros menores ao longo de bilhões de anos.\n",
       "*   **Buracos Negros de Massa Intermediária:** Com massas entre buracos negros estelares e supermassivos. Sua formação é menos compreendida, mas podem se formar a partir da fusão de buracos negros estelares em aglomerados estelares densos ou através do colapso direto de nuvens de gás massivas no universo primitivo.\n",
       "*   **Buracos Negros Primordiais:** Uma classe hipotética de buracos negros que se acredita terem se formado nos primeiros momentos após o Big Bang, quando o universo era extremamente denso e instável. Suas massas poderiam variar amplamente, desde tamanhos subatômicos até massas estelares.\n",
       "\n",
       "Em resumo, a formação de buracos negros é um resultado direto da lei da gravidade, atuando em condições extremas de densidade e massa, tipicamente observadas no final da vida de estrelas massivas. A relatividade geral fornece o arcabouço teórico para entender a natureza e o comportamento dessas entidades cósmicas.\n",
       "\n",
       "Existe algum aspecto específico da formação de buracos negros que você gostaria de aprofundar?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "A seguir está uma conversa com um assistente de pesquisa de IA. O tom do assistente é técnico e científico.\n",
    "\n",
    "Humano: Olá, quem é você?\n",
    "IA: Saudações! Sou um assistente de pesquisa de IA. Como posso ajudá-lo hoje?\n",
    "Humano: Você pode me falar sobre a criação de buracos negros?\n",
    "IA:\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd6893f-fa28-4595-8008-56ed6e1f6cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Claro! Imagine que as estrelas são como bolas de fogo gigantes no espaço. A maioria das estrelas é como o nosso Sol. Mas algumas estrelas são MUITO, MUITO maiores.\n",
       "\n",
       "Quando uma estrela gigante fica muito velha e esgota todo o seu combustível, ela não consegue mais se sustentar. É como se o ar de um balão estourasse!\n",
       "\n",
       "Quando isso acontece com estrelas muito, muito grandes, elas encolhem MUITO, MUITO rápido. E quando elas encolhem tão apertado, elas se tornam algo super denso e pesado chamado buraco negro.\n",
       "\n",
       "Pense em algo que é tão pesado que nem mesmo a luz consegue escapar dele. É por isso que eles são chamados de \"buracos negros\" – porque não conseguimos vê-los diretamente! É como um ralo gigante no espaço que suga tudo o que chega muito perto.\n",
       "\n",
       "Então, para criar um buraco negro, você precisa de uma estrela SUPER gigante que morre de uma maneira especial.\n",
       "\n",
       "Você tem mais alguma pergunta sobre buracos negros?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "\"\"\"\n",
    "A seguir está uma conversa com um assistente de pesquisa de IA. As respostas do assistente devem ser fáceis de entender até mesmo por estudantes do ensino fundamental.\n",
    "\n",
    "Humano: Olá, quem é você?\n",
    "IA: Saudações! Sou um assistente de pesquisa de IA. Como posso ajudá-lo hoje?\n",
    "Humano: Você pode me falar sobre a criação de buracos negros?\n",
    "IA:\n",
    "\"\"\"\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e2575-4d02-4327-8ce2-36b3ec199e84",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353da7e8-10d9-45ee-81d5-92029126feab",
   "metadata": {},
   "source": [
    "### Raciocínio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e84e9b3-c062-45c0-b1a9-e0c0eb69fab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "9.000 * 9.000 = **81.000.000**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Quanto é 9.000 * 9.000?\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d49458c-c332-4766-92b1-ca87f7c22cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sim"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Somente responda se estou certo e mais nada.\n",
    "\n",
    "Os números ímpares neste grupo somam um número par: 15, 32, 5, 13, 82, 7, 1.\n",
    "\n",
    "Estou certo?\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cded4558-dc38-4e45-b75a-475a6360fa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Etapa 1: Identificar os números ímpares**\n",
       "\n",
       "Os números ímpares no grupo são: 15, 5, 13, 7, 1.\n",
       "\n",
       "**Etapa 2: Somar os números ímpares**\n",
       "\n",
       "15 + 5 + 13 + 7 + 1 = 41\n",
       "\n",
       "**Etapa 3: Indicar se o resultado é ímpar ou par**\n",
       "\n",
       "O resultado (41) é um número **ímpar**."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let response = await model.invoke(`\n",
    "Os números ímpares neste grupo somam um número par: 15, 32, 5, 13, 82, 7, 1. \n",
    "\n",
    "Resolva dividindo o problema em etapas, mas de forma sucinta.\n",
    "Primeiro, identifique os números ímpares, some-os e indique se o resultado é ímpar ou par.\n",
    "`)\n",
    "\n",
    "await display.md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a395a-d158-4893-be08-1a85bcec7c66",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
